{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<font color= green>Accenture - Sentiment Analysis<font/>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=purple>Load Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "dataset_path = 'DataSet/'\n",
    "df=pd.read_csv(dataset_path+'IMDB Dataset.csv', sep=',',header=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=purple>Clean and Preprocess</font>\n",
    "**Remove special characters**<br>\n",
    "Definition and replace of the special characters for a space or empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "df = df.replace(REPLACE_NO_SPACE, '')\n",
    "df = df.replace(REPLACE_WITH_SPACE, ' ')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to **stratify** the data and divide the data into a **Train** and **Test** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN, TEST = train_test_split(df, test_size=0.5, stratify= df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subdivide each set into **X** and **Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = TRAIN['review']\n",
    "Xtest = TEST['review']\n",
    "\n",
    "Ytrain = TRAIN['sentiment']\n",
    "Ytest = TEST['sentiment']\n",
    "Xtrain.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=purple>Vectorization</font>\n",
    "\n",
    "In order to apply our machine learning algoritmos and therefore build an intelligent classifier, we must convert each review to a **numeric representation**. This process is called ***vectorization***. \n",
    "\n",
    "There are several ways to do tf-idf transformation but in a nutshell, tf-idf aims to represent the number of times a given word appears in a document (a movie review in our case) relative to the number of documents in the corpus that the word appears in â€” where words that appear in many documents have a value closer to zero and words that appear in less documents have values closer to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Xtrain = TRAIN['review']\n",
    "Xtest = TEST['review']\n",
    "Ytrain = TRAIN['sentiment']\n",
    "Ytest = TEST['sentiment']\n",
    "\n",
    "tfidf = TfidfVectorizer(binary=True, ngram_range=(1,2), stop_words='english')\n",
    "tfidf.fit(Xtrain)\n",
    "Xtrain = tfidf.transform(Xtrain)\n",
    "Xtest = tfidf.transform(Xtest)\n",
    "\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=purple>Designing Phase</font>\n",
    "\n",
    "In this phase, the **Xtrain** set is subdivided into another *train* and *test* set, in order to tune the parameters of our classifier and decide which tune we consider to be **optimal** for the **performance** of our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xtrain, Ytrain, train_size = 0.8)\n",
    "\n",
    "for c in [0.01, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4]:\n",
    "    svc = LinearSVC(C=c)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    print('Accuracy for C=%s: %s' % (c, accuracy_score(Y_test, svc.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=purple>Train The Final Classifier</font>\n",
    "Now that we know the optimal parameters for the design of our classifier, we must train a **new classifier** using the entire Train set (**Xtrain**) and then evaluate its performance with the Test set (**Xtest,Ytest**) based on the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classifier = LinearSVC(C=3.5, max_iter=300)\n",
    "final_classifier.fit(Xtrain,Ytrain)\n",
    "print('Final Accuracy: %s' % accuracy_score(Ytest, final_classifier.predict(Xtest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
